---
layout: default
title: "R&eacute;mi Bardenet"
description: "Welcome!"
---

<section>
    <h1> Research </h1>

    <p>Under construction. I plan to put here a brief non-technical summary of my research activities.</p>

</section>


<!--
<section>
        <h1> Research </h1>


    
<p>Here are some of my currently active research topics:</p>

</section>

<section>
<aside>
	<img src="/img/mcmc.png" alt="mcmc pic"
	style="width:110px;">
</aside>
<article>         
	<p>
        <strong> Markov chain Monte Carlo (MCMC)</strong> algorithms are
        popular numerical integration methods when the dimension of the input space is large, say larger than 10. This is often the case in applications of Bayesian inference. I am interested in MCMC methodology at large, with a focus at the moment at the particular setting of <strong>Bayesian inference with big datasets</strong>. Indeed, vanilla MCMC for Bayesian inference is an iterative procedure thtat sweeps over all data millions of time. When the number of data points in the dataset is large, these repeated sweeps become a bottleneck.
  </p>
</article>
</section>

<section>
<aside>
	<img src="/img/dpp.png" alt="dpp pic"
	style="width:140px;">
</aside>
<article>         
	<p>
        A <strong> determinantal point process</strong> is a
        distribution over clouds of points, where the points repell
        each other. Realizations typically look like well-spread point
        patterns. DPPs have appeared in suprisingly many domains,
such as statistical physics, random matrix theory, or number
      theory. Recently, they have appeared in applied mathematics and computer science as a puzzling modeling and analysis tool.
     
     
        </p>
</article>
</section>

<section>
    <aside>
	      <img src="/img/cell.png" alt="cell pic"
	           style="width:140px;">
    </aside>
    <article>         
	      <p>
            
        </p>
    </article>
</section>
-->
